
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "results/mon_uncertainty_propagation.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_results_mon_uncertainty_propagation.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_results_mon_uncertainty_propagation.py:


LH2pac Uncertainty propagation
=======================

In this section,
we will propagate uncertainties through a discipline

.. GENERATED FROM PYTHON SOURCE LINES 9-10

Packages import

.. GENERATED FROM PYTHON SOURCE LINES 10-24

.. code-block:: default

    from importlib.metadata import distribution
    from numpy import array
    from gemseo.api import create_surrogate
    from gemseo_mlearning.api import sample_discipline
    from discipline import H2TurboFan
    from mon_uncertain_space import lh2pacUncertainSpace
    from gemseo.uncertainty.api import create_statistics
    from gemseo_mlearning.api import sample_discipline
    from gemseo.mlearning.qual_measure.r2_measure import R2Measure
    from matplotlib import pyplot as plt
    import numpy as np
    import pandas as pd



.. GENERATED FROM PYTHON SOURCE LINES 25-28

In this first section we want to do some statistics on the dataset sampeled with the real model
Firstly,
we call the lh2pac uncertain space

.. GENERATED FROM PYTHON SOURCE LINES 28-30

.. code-block:: default

    uncertain_space = lh2pacUncertainSpace()


.. GENERATED FROM PYTHON SOURCE LINES 31-33

We compute the variation coefficient of the input parameters so that we can compare
it with the output parameters

.. GENERATED FROM PYTHON SOURCE LINES 33-41

.. code-block:: default

    names = ["tgi","tvi","sfc","mass","drag"]
    dic = {}
    print ("{:<8} {:<15}".format('Feature', 'Variation_coef %'))
    for name in names:
        distribution = uncertain_space.distributions[name]
        print(name, "     ", distribution.standard_deviation / distribution.mean * 100)



.. GENERATED FROM PYTHON SOURCE LINES 42-44

Then,
we call the discipline H2TurboFan:

.. GENERATED FROM PYTHON SOURCE LINES 44-46

.. code-block:: default

    discipline = H2TurboFan()


.. GENERATED FROM PYTHON SOURCE LINES 47-49

Thirdly,
we sample the discipline with a Monte Carlo algorithm:

.. GENERATED FROM PYTHON SOURCE LINES 49-52

.. code-block:: default

    dataset = sample_discipline(discipline, uncertain_space, output_names=["mtow"], algo_name="OT_MONTE_CARLO", n_samples=30)



.. GENERATED FROM PYTHON SOURCE LINES 53-56

Lastly,
we create a statistics object to estimate statistics,
such as mean, variance and variation coefficient:

.. GENERATED FROM PYTHON SOURCE LINES 56-66

.. code-block:: default

    statistics = create_statistics(dataset)
    mean = statistics.compute_mean()
    variance = statistics.compute_standard_deviation()
    cv = statistics.compute_variation_coefficient()
    names = ["tgi","tvi","sfc","mass","drag", "mtow"]
    print ("{:<8} {:<15} {:<10} {:<10}".format('Feature','Mean','std','Variation_coefficient %'))
    for name in names:
        print("{:<8} {:<15} {:<10} {:<10}".format(name, "{:.2f}".format(mean[name][0]),\
             "{:.2f}".format(np.sqrt(variance[name][0])),"{:.2f}".format(cv[name][0]*100)))


.. GENERATED FROM PYTHON SOURCE LINES 67-68

We can also plot the histogram of the variables in the dataset:

.. GENERATED FROM PYTHON SOURCE LINES 68-76

.. code-block:: default

    fig, axes = plt.subplots(2, 3)
    for i in range(2):
        for ax, name in zip(axes[i], names):
            ax.hist(dataset[name])
            ax.set_title(name)
    plt.show()



.. GENERATED FROM PYTHON SOURCE LINES 77-79

In this second section we want to do some statistics on the dataset sampeled with the surrogate model
so we can compare them with those of the dataset made with our true model 

.. GENERATED FROM PYTHON SOURCE LINES 79-87

.. code-block:: default

    surrogate_discipline = create_surrogate("LinearRegressor", dataset)
    r2 = R2Measure(surrogate_discipline.regression_model, True)
    print("R2: learning measure = \n", r2.evaluate_learn())  # learning measure
    print("R2: k-folds cross-validation measure = \n", r2.evaluate_kfolds())  # k-folds cross-validation measure
    #The learning measure equals to 0.997, hence the linear regression is a good fit for the surrogate model.

    surrogate_dataset = sample_discipline(surrogate_discipline, uncertain_space, output_names=["mtow"], algo_name="OT_MONTE_CARLO", n_samples=30)


.. GENERATED FROM PYTHON SOURCE LINES 88-91

Lastly,
we create an :class:`.EmpiricalStatistics` object to estimate statistics,
such as mean and variance:

.. GENERATED FROM PYTHON SOURCE LINES 91-102

.. code-block:: default

    surrogate_statistics = create_statistics(surrogate_dataset)
    s_mean = surrogate_statistics.compute_mean()
    s_variance = surrogate_statistics.compute_standard_deviation()
    s_cv = surrogate_statistics.compute_variation_coefficient()
    names = ["tgi","tvi","sfc","mass","drag", "mtow"]
    print ("{:<8} {:<15} {:<10} {:<10}".format('Feature','Mean','std','Variation_coefficient %'))
    for name in names:
        print("{:<8} {:<15} {:<10} {:<10}".format(name, "{:.2f}".format(s_mean[name][0]),\
             "{:.2f}".format(np.sqrt(s_variance[name][0])),"{:.2f}".format(s_cv[name][0]*100)))



.. GENERATED FROM PYTHON SOURCE LINES 103-104

We can also plot the histogram of the variables in the surrogate_dataset:

.. GENERATED FROM PYTHON SOURCE LINES 104-112

.. code-block:: default

    fig, axes = plt.subplots(2, 3)
    for i in range(2):
        for ax, name in zip(axes[i], names):
            ax.hist(surrogate_dataset[name])
            ax.set_title(name)
    plt.show()




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.000 seconds)


.. _sphx_glr_download_results_mon_uncertainty_propagation.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: mon_uncertainty_propagation.py <mon_uncertainty_propagation.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: mon_uncertainty_propagation.ipynb <mon_uncertainty_propagation.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

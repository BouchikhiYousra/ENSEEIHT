
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "results/mon_surrogate.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_results_mon_surrogate.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_results_mon_surrogate.py:


Surrogate model
===============

In this example,
we will build a surrogate model of the Rosenbrock function
and a constraint related to an Rosenbrock-based optimization problem.

.. GENERATED FROM PYTHON SOURCE LINES 9-21

.. code-block:: default


    from gemseo.api import create_scenario
    from gemseo.api import create_surrogate
    from gemseo.api import import_discipline
    from gemseo.mlearning.qual_measure.r2_measure import R2Measure
    from gemseo.mlearning.qual_measure.rmse_measure import RMSEMeasure
    from gemseo_mlearning.api import sample_discipline
    from discipline import H2TurboFan
    from mon_design_space import lh2pacDesignSpace
    from marilib.utils import unit
    import matplotlib.pyplot as plt


.. GENERATED FROM PYTHON SOURCE LINES 22-24

Firstly,
we import the design_space

.. GENERATED FROM PYTHON SOURCE LINES 24-28

.. code-block:: default

    from numpy import array

    discipline = H2TurboFan()


.. GENERATED FROM PYTHON SOURCE LINES 29-30

Then, we import the design space:

.. GENERATED FROM PYTHON SOURCE LINES 30-33

.. code-block:: default

    design_space = lh2pacDesignSpace()
    print(design_space)


.. GENERATED FROM PYTHON SOURCE LINES 34-36

Then,
we sample the discipline with an optimal LHS:

.. GENERATED FROM PYTHON SOURCE LINES 36-38

.. code-block:: default

    dataset = sample_discipline(discipline, design_space, output_names=["mtow","tofl","vapp", "vz_mcl","vz_mcr","oei_path","ttc","far"],algo_name= "OT_OPT_LHS", n_samples= 30)


.. GENERATED FROM PYTHON SOURCE LINES 39-41

before creating a surrogate discipline:
surrogate_discipline = create_surrogate("RBFRegressor", dataset)

.. GENERATED FROM PYTHON SOURCE LINES 41-42

.. code-block:: default

    surrogate_discipline = create_surrogate("GaussianProcessRegressor", dataset)

.. GENERATED FROM PYTHON SOURCE LINES 43-44

and using it for prediction:

.. GENERATED FROM PYTHON SOURCE LINES 44-47

.. code-block:: default

    surrogate_discipline.execute({"x": array([1.])})
    print(surrogate_discipline.cache.last_entry)


.. GENERATED FROM PYTHON SOURCE LINES 48-49

optimization of the surrogate model

.. GENERATED FROM PYTHON SOURCE LINES 49-60

.. code-block:: default


    #first we create a scenario
    scenario = create_scenario([surrogate_discipline], "DisciplinaryOpt", "mtow", design_space)
    scenario.add_constraint("tofl", "ineq", positive=False, value = 2200)
    scenario.add_constraint("vapp", "ineq", positive=False, value = 137)
    scenario.add_constraint("vz_mcl", "ineq", positive=True, value = unit.ftpmin_mps(300))
    scenario.add_constraint("vz_mcr", "ineq", positive=True, value = unit.ftpmin_mps(0))
    scenario.add_constraint("oei_path", "ineq", positive=True, value=0.0011)
    scenario.add_constraint("ttc", "ineq", positive=False, value=unit.min_s(25))
    scenario.add_constraint("far", "ineq", positive=True, value=13.4)


.. GENERATED FROM PYTHON SOURCE LINES 61-62

before executing it with a gradient-free optimizer:

.. GENERATED FROM PYTHON SOURCE LINES 62-64

.. code-block:: default

    scenario.execute({"algo": "NLOPT_COBYLA", "max_iter": 30})


.. GENERATED FROM PYTHON SOURCE LINES 65-70

Lastly,
 we can plot the optimization history:
scenario.post_process("OptHistoryView", save=True, show=False)
 Workaround for HTML rendering, instead of ``show=True``
plt.show()

.. GENERATED FROM PYTHON SOURCE LINES 72-75

This surrogate discipline can be used in a scenario.
The underlying regression model can also be assessed,
with the R2 measure for instance:

.. GENERATED FROM PYTHON SOURCE LINES 75-80

.. code-block:: default

    r2 = R2Measure(surrogate_discipline.regression_model, True)
    print("r2 de l'evaluate_learn",r2.evaluate_learn())  # learning measure
    print("\n\n")
    print("r2 de l'evaluate_kfolds",r2.evaluate_kfolds())  # k-folds cross-validation measure
    print("\n\n")

.. GENERATED FROM PYTHON SOURCE LINES 81-82

or with the root mean squared error:

.. GENERATED FROM PYTHON SOURCE LINES 82-93

.. code-block:: default

    rmse = RMSEMeasure(surrogate_discipline.regression_model, True)
    print("rmse de evaluate_learn",rmse.evaluate_learn())
    print("\n\n")
    print("rmse de evaluate_kfolds",rmse.evaluate_kfolds())
    print("\n\n")

    surrogate_discipline.serialize("mon_surrogate.pkl")

    discipline = import_discipline("mon_surrogate.pkl")
    discipline.execute({"x": array([1.])})
    print(discipline.get_output_data())


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.000 seconds)


.. _sphx_glr_download_results_mon_surrogate.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: mon_surrogate.py <mon_surrogate.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: mon_surrogate.ipynb <mon_surrogate.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
